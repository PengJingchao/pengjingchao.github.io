# 模式识别原理与应用
## 基础知识：最优化方法，梯度下降法，最小二乘法

### 问题的一般形式：
最优化问题数学模型的标准形式：<br />
<img src="http://latex.codecogs.com/gif.latex?min\,&space;f(x)" title="min\, f(x)" /><br />
<img src="http://latex.codecogs.com/gif.latex?s.t.\:g(x)\geqslant&space;0;" title="s.t.\:g(x)\geqslant 0;" />

多元函数的最优化问题写成矩阵形式为：<br />
<img src="http://latex.codecogs.com/gif.latex?min\;&space;f(\mathbf{x})" title="min\; f(\mathbf{x})" /><br />
<img src="http://latex.codecogs.com/gif.latex?\left\{\begin{matrix}&space;\mathbf{G}(\mathbf{X})&space;\geqslant&space;0\\&space;\mathbf{H}(\mathbf{X})&space;=&space;0&space;\end{matrix}\right." title="\left\{\begin{matrix} \mathbf{G}(\mathbf{X}) \geqslant 0\\ \mathbf{H}(\mathbf{X}) = 0 \end{matrix}\right." />

### 梯度下降法
  梯度下降法（Gradient descent）是求解一阶最优化算法，原理是在对应点的梯度的反方向上按规定步长进行迭代搜索，通常也称为最速下降法。<br />
一元函数的泰勒展开：<br /><img src="http://latex.codecogs.com/gif.latex?f(&space;x_{0}&plus;h)=f(x_{0})&plus;{f}'(x_{0})h&plus;\frac{{f}''(x_{0})}{2!}h^{2}&plus;..." title="f( x_{0}+h)=f(x_{0})+{f}'(x_{0})h+\frac{{f}''(x_{0})}{2!}h^{2}+..." /><br />
多元函数的泰勒展开：<br /><img src="http://latex.codecogs.com/gif.latex?f(&space;\mathbf{x_{0}}&plus;\mathbf{h})=f(\mathbf{x_{0}})&plus;{(\bigtriangledown&space;{f}(\mathbf{x_{0}}))^{T}}\mathbf{h}&plus;\frac{1}{2!}\mathbf{h}^{T}(\bigtriangledown{f}(\mathbf{x_{0}}))^{2}\mathbf{h}&plus;..." title="f( \mathbf{x_{0}}+\mathbf{h})=f(\mathbf{x_{0}})+{(\bigtriangledown {f}(\mathbf{x_{0}}))^{T}}\mathbf{h}+\frac{1}{2!}\mathbf{h}^{T}(\bigtriangledown{f}(\mathbf{x_{0}}))^{2}\mathbf{h}+..." /><br />
其中，<br /><img src="http://latex.codecogs.com/gif.latex?\mathbf{x_{0}}\in&space;\mathbb{R}^{d\times&space;1}" title="\mathbf{x_{0}}\in \mathbb{R}^{d\times 1}" /><br />
即:<br /><img src="http://latex.codecogs.com/gif.latex?\begin{bmatrix}x_{1}&space;\\&space;x_{2}&space;\\&space;...&space;\\&space;x_{d}&space;\end{bmatrix}" title="\begin{bmatrix}x_{1} \\ x_{2} \\ ... \\ x_{d} \end{bmatrix}" /><br />
